#!/usr/bin/env python3
"""
Interfejs wiersza poleceÅ„ dla analizy tokenÃ³w
Wspiera multiprocessing, tqdm i wybÃ³r forÃ³w
"""

import os
import sys
import argparse
import time
from pathlib import Path
from typing import List, Optional

# Dodaj Å›cieÅ¼kÄ™ do moduÅ‚u analizy
sys.path.append(str(Path(__file__).parent))

from tokenization import TokenAnalyzer
from gender_prediction import run_gender_rules, run_gender_rules_into_analysis
from config import get_config
from topic_modeling.batch_classifier import run_batch_classification

class AnalysisCLI:
    """Interfejs wiersza poleceÅ„ dla analizy"""
    
    def __init__(self):
        self.config = get_config()
        self.analyzer = None
    
    def setup_analyzer(self, source_db: str, analysis_db: str, forums: List[str] = None):
        """Konfiguruje analizator"""
        try:
            # JeÅ¼eli fora nie zostaÅ‚y podane, pozwÃ³l analizatorowi wykryÄ‡ je z bazy
            if forums is None or (isinstance(forums, list) and len(forums) == 0) or forums == ['auto']:
                forums = None
            
            self.analyzer = TokenAnalyzer(
                source_db=source_db,
                analysis_db=analysis_db,
                forums_to_analyze=forums
            )
            
            print(f"âœ… Analizator skonfigurowany")
            print(f"   ğŸ“ Baza ÅºrÃ³dÅ‚owa: {source_db}")
            print(f"   ğŸ“ Baza analizy: {analysis_db}")
            if forums is None:
                print(f"   ğŸ¯ Fora do analizy: (auto) zostanÄ… wykryte z bazy")
            else:
                print(f"   ğŸ¯ Fora do analizy: {', '.join(forums)}")
            print(f"   âš¡ Multiprocessing: {'WÅ‚Ä…czone' if self.config['multiprocessing']['use_multiprocessing'] else 'WyÅ‚Ä…czone'}")
            print(f"   ğŸ”§ Liczba procesÃ³w: {self.config['multiprocessing']['max_workers']}")
            
            return True
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d konfiguracji analizatora: {e}")
            return False
    
    def create_database(self) -> bool:
        """Tworzy bazÄ™ analizy"""
        try:
            print("ğŸ—ï¸  Tworzenie bazy analizy...")
            
            if self.analyzer.create_analysis_database():
                print("âœ… Baza analizy utworzona pomyÅ›lnie")
                return True
            else:
                print("âŒ BÅ‚Ä…d tworzenia bazy analizy")
                return False
                
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d tworzenia bazy: {e}")
            return False
    
    def show_forums_info(self):
        """Pokazuje informacje o forach"""
        try:
            if not self.analyzer:
                print("âŒ Analizator nie jest skonfigurowany")
                return False
            
            print("ğŸ“Š INFORMACJE O FORACH")
            print("=" * 50)
            
            forums_info = self.analyzer.get_forums_info()
            
            for forum in forums_info['forums']:
                print(f"ğŸ¯ {forum['name']}")
                print(f"   ğŸ“ Wszystkie posty: {forum['total_posts']:,}")
                print(f"   ğŸ” Przeanalizowane: {forum['analyzed_posts']:,}")
                print(f"   ğŸ“ˆ PostÄ™p: {forum['progress']:.1f}%")
                print()
            
            return True
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d pobierania informacji o forach: {e}")
            return False
    
    def analyze_single_batch(self, batch_size: int) -> bool:
        """Analizuje pojedynczÄ… partiÄ™ postÃ³w"""
        try:
            if not self.analyzer:
                print("âŒ Analizator nie jest skonfigurowany")
                return False
            
            print(f"ğŸ“¦ Analiza partii {batch_size} postÃ³w...")
            
            start_time = time.time()
            processed = self.analyzer.process_batch(batch_size)
            elapsed = time.time() - start_time
            
            if processed > 0:
                print(f"âœ… Przetworzono {processed} postÃ³w w {elapsed:.2f}s")
                print(f"   âš¡ WydajnoÅ›Ä‡: {processed/elapsed:.1f} postÃ³w/s")
            else:
                print("â„¹ï¸  Brak postÃ³w do analizy")
            
            return True
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d analizy partii: {e}")
            return False
    
    def analyze_all_posts(self, show_progress: bool = True) -> bool:
        """Analizuje wszystkie posty z okreÅ›lonych forÃ³w"""
        try:
            if not self.analyzer:
                print("âŒ Analizator nie jest skonfigurowany")
                return False
            
            print("ğŸš€ Rozpoczynam analizÄ™ wszystkich postÃ³w...")
            
            start_time = time.time()
            result = self.analyzer.analyze_all_forums_posts(show_progress=show_progress)
            elapsed = time.time() - start_time
            
            if 'error' not in result:
                print(f"\nâœ… Analiza zakoÅ„czona!")
                print(f"   ğŸ“ Przeanalizowane posty: {result['total_analyzed']:,}")
                print(f"   ğŸ¯ Wszystkie posty: {result['total_posts']:,}")
                print(f"   â±ï¸  Czas wykonania: {elapsed:.2f}s")
                print(f"   âš¡ Åšrednia wydajnoÅ›Ä‡: {result['total_analyzed']/elapsed:.1f} postÃ³w/s")
                print(f"   ğŸ¯ Fora: {', '.join(result['forums_analyzed'])}")
                return True
            else:
                print(f"âŒ BÅ‚Ä…d analizy: {result['error']}")
                return False
                
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d analizy wszystkich postÃ³w: {e}")
            return False
    
    def show_summary(self):
        """Pokazuje podsumowanie analizy"""
        try:
            if not self.analyzer:
                print("âŒ Analizator nie jest skonfigurowany")
                return False
            
            print("ğŸ“Š PODSUMOWANIE ANALIZY")
            print("=" * 50)
            
            summary = self.analyzer.get_analysis_summary()
            
            if summary:
                print(f"ğŸ“ Wszystkie posty: {summary['total_posts']:,}")
                print(f"ğŸ” Przeanalizowane: {summary['total_analyzed']:,}")
                print(f"ğŸ“ˆ PostÄ™p: {summary['analysis_progress']:.1f}%")
                print(f"ğŸ”¢ ÅÄ…czna liczba tokenÃ³w: {summary['total_tokens']:,}")
                print(f"ğŸ“ ÅÄ…czna liczba sÅ‚Ã³w: {summary['total_words']:,}")
                
                # Statystyki dzienne
                if summary['daily_stats']:
                    print(f"\nğŸ“… Statystyki dzienne:")
                    for day in summary['daily_stats'][:5]:  # PokaÅ¼ ostatnie 5 dni
                        print(f"   ğŸ“… {day['date']}: {day['posts_analyzed']} postÃ³w, {day['total_tokens']:,} tokenÃ³w")
                
                # Statystyki pamiÄ™ci
                if 'memory_stats' in summary:
                    mem_stats = summary['memory_stats']
                    print(f"\nğŸ’¾ Statystyki pamiÄ™ci:")
                    print(f"   ğŸ” Posty przeanalizowane: {mem_stats.get('total_posts_analyzed', 0):,}")
                    print(f"   âŒ BÅ‚Ä™dy przetwarzania: {mem_stats.get('processing_errors', 0)}")
                    print(f"   ğŸ¤– Tokeny spaCy: {mem_stats.get('spacy_tokens', 0):,}")
                    print(f"   ğŸ”¢ Tokeny proste: {mem_stats.get('simple_tokens', 0):,}")
                
                return True
            else:
                print("âŒ Nie udaÅ‚o siÄ™ pobraÄ‡ podsumowania")
                return False
                
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d pobierania podsumowania: {e}")
            return False
    
    def run_continuous_analysis(self, interval: int, batch_size: int):
        """Uruchamia ciÄ…gÅ‚Ä… analizÄ™"""
        try:
            if not self.analyzer:
                print("âŒ Analizator nie jest skonfigurowany")
                return False
            
            print(f"ğŸ”„ Uruchamiam ciÄ…gÅ‚Ä… analizÄ™ (interwaÅ‚: {interval}s, partia: {batch_size})")
            print("   NaciÅ›nij Ctrl+C aby zatrzymaÄ‡")
            
            self.analyzer.start_continuous_analysis(interval, batch_size)
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ Zatrzymano analizÄ™ (Ctrl+C)")
            if self.analyzer:
                self.analyzer.stop_continuous_analysis()
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d ciÄ…gÅ‚ej analizy: {e}")

def main():
    """GÅ‚Ã³wna funkcja CLI"""
    parser = argparse.ArgumentParser(
        description="Analiza tokenÃ³w dla postÃ³w forum z multiprocessing i tqdm",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PrzykÅ‚ady uÅ¼ycia:
  python cli.py --create-db                    # UtwÃ³rz bazÄ™ analizy
  python cli.py --info                         # PokaÅ¼ informacje o forach
  python cli.py --batch 100                    # Analizuj partiÄ™ 100 postÃ³w
  python cli.py --all                          # Analizuj wszystkie posty
  python cli.py --continuous --interval 300    # CiÄ…gÅ‚a analiza co 5 minut
  python cli.py --summary                      # PokaÅ¼ podsumowanie
  python cli.py --forums radio_katolik,wiara   # Wybierz fora do analizy
        """
    )
    
    # Opcje bazy danych
    parser.add_argument("--source-db", default="../data/databases/merged_forums.db",
                       help="ÅšcieÅ¼ka do ÅºrÃ³dÅ‚owej bazy danych")
    parser.add_argument("--analysis-db", default="../data/databases/analysis_forums.db",
                       help="ÅšcieÅ¼ka do bazy analizy")
    
    # Opcje forÃ³w
    parser.add_argument("--forums", 
                       help="Lista forÃ³w do analizy (oddzielone przecinkami)")
    
    # Opcje multiprocessing
    parser.add_argument("--no-multiprocessing", action="store_true",
                       help="WyÅ‚Ä…cz multiprocessing")
    parser.add_argument("--workers", type=int,
                       help="Liczba procesÃ³w roboczych")
    parser.add_argument("--chunk-size", type=int,
                       help="Rozmiar chunka dla multiprocessing")
    
    # Akcje
    parser.add_argument("--create-db", action="store_true",
                       help="UtwÃ³rz bazÄ™ analizy")
    parser.add_argument("--info", action="store_true",
                       help="PokaÅ¼ informacje o forach")
    parser.add_argument("--batch", type=int, metavar="SIZE",
                       help="Analizuj partiÄ™ postÃ³w o okreÅ›lonym rozmiarze")
    parser.add_argument("--all", action="store_true",
                       help="Analizuj wszystkie posty z okreÅ›lonych forÃ³w")
    # Nowy etap: predykcja pÅ‚ci
    parser.add_argument("--gender-rules", action="store_true",
                       help="Uruchom predykcjÄ™ pÅ‚ci na podstawie reguÅ‚ jÄ™zykowych (rules_v1)")
    parser.add_argument("--gender-rules-crossdb", action="store_true",
                       help="Predykcja pÅ‚ci: czytaj z --source-db (forum_*.db), zapisz do --analysis-db (gender_predictions)")
    parser.add_argument("--continuous", action="store_true",
                       help="Uruchom ciÄ…gÅ‚Ä… analizÄ™")
    parser.add_argument("--summary", action="store_true",
                       help="PokaÅ¼ podsumowanie analizy")
    # Klasyfikacja LLM ws. taksonomii
    parser.add_argument("--llm-classify", action="store_true",
                       help="Uruchom klasyfikacjÄ™ postÃ³w z Excela przez OpenAI Batch API")
    parser.add_argument("--llm-input", type=str, default="data/topics/results/20250821/M/ALL/185832/examples/topic_2_pi_pis_sld.xlsx",
                       help="ÅšcieÅ¼ka do wejÅ›ciowego pliku Excel z kolumnÄ… 'content' (i opcjonalnie 'post_id')")
    parser.add_argument("--llm-batch-size", type=int, default=10,
                       help="Rozmiar batcha (liczba postÃ³w na job Batch API)")
    parser.add_argument("--llm-interval", type=int, default=10,
                       help="InterwaÅ‚ pollingu statusu batcha (sekundy)")
    
    # Opcje ciÄ…gÅ‚ej analizy
    parser.add_argument("--interval", type=int, default=300,
                       help="InterwaÅ‚ dla ciÄ…gÅ‚ej analizy w sekundach")
    parser.add_argument("--batch-size", type=int, default=100,
                       help="Rozmiar partii dla analizy")
    
    # Opcje wyÅ›wietlania
    parser.add_argument("--no-progress", action="store_true",
                       help="WyÅ‚Ä…cz paski postÄ™pu")
    
    args = parser.parse_args()
    
    # SprawdÅº czy podano akcjÄ™
    if not any([args.create_db, args.info, args.batch, args.all, args.continuous, args.summary, args.gender_rules, args.gender_rules_crossdb, args.llm_classify]):
        parser.print_help()
        return False
    
    # UtwÃ³rz CLI
    cli = AnalysisCLI()
    
    # Konfiguruj multiprocessing jeÅ›li podano
    if args.no_multiprocessing:
        cli.config['multiprocessing']['use_multiprocessing'] = False
    
    if args.workers:
        cli.config['multiprocessing']['max_workers'] = args.workers
    
    if args.chunk_size:
        cli.config['multiprocessing']['chunk_size'] = args.chunk_size
    
    # Parsuj fora
    forums = None
    if args.forums:
        forums = [f.strip() for f in args.forums.split(',')]
    
    # Konfiguruj analizator
    if not cli.setup_analyzer(args.source_db, args.analysis_db, forums):
        return False
    
    # Wykonaj akcje
    success = True
    
    if args.create_db:
        success &= cli.create_database()
    
    if args.info:
        success &= cli.show_forums_info()
    
    if args.batch:
        success &= cli.analyze_single_batch(args.batch)
    
    if args.all:
        success &= cli.analyze_all_posts(show_progress=not args.no_progress)
    
    if args.summary:
        success &= cli.show_summary()

    if args.gender_rules:
        # Uruchom prosty predyktor pÅ‚ci dla wybranych forÃ³w (lub wszystkich wykrytych)
        forums_list = forums
        if forums_list is None:
            # Wykryj fora z bazy analizy (tak jak w TokenAnalyzer)
            try:
                import sqlite3
                conn = sqlite3.connect(args.analysis_db)
                cur = conn.cursor()
                cur.execute("SELECT spider_name FROM forums")
                forums_list = [row[0] for row in cur.fetchall()]
                conn.close()
            except Exception:
                forums_list = None
        print("\n=== Predykcja pÅ‚ci (rules_v1) ===")
        res = run_gender_rules(args.analysis_db, forums=forums_list)
        print(f"UÅ¼ytkownicy przetworzeni: {res.get('processed_users', 0)}")
        print(f"Zapisane predykcje: {res.get('saved_predictions', 0)}")

    if args.gender_rules_crossdb:
        # Cross-DB: czytamy ze ÅºrÃ³dÅ‚a (forum_*.db), zapisujemy do bazy analizy
        forums_list = forums
        if forums_list is None:
            # Wykryj fora ze ÅºrÃ³dÅ‚a
            try:
                import sqlite3
                conn = sqlite3.connect(args.source_db)
                cur = conn.cursor()
                cur.execute("SELECT spider_name FROM forums")
                forums_list = [row[0] for row in cur.fetchall()]
                conn.close()
            except Exception:
                forums_list = None

        print("\n=== Predykcja pÅ‚ci (rules_v1, cross-DB) ===")
        try:
            res = run_gender_rules_into_analysis(
                analysis_db=args.analysis_db,
                source_db=args.source_db,
                forums=forums_list,
            )
            print(f"UÅ¼ytkownicy przetworzeni: {res.get('processed_users', 0)}")
            print(f"Zapisane predykcje: {res.get('saved_predictions', 0)}")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d predykcji (cross-DB): {e}")
    
    if args.llm_classify:
        print("\n=== Klasyfikacja LLM (Batch API) ===")
        try:
            res = run_batch_classification(
                excel_path=args.llm_input,
                batch_size=args.llm_batch_size,
                poll_interval_s=args.llm_interval,
            )
            print("Wyniki zapisane w:")
            print(f"  run_dir: {res.get('run_dir')}")
            print(f"  taxonomy: {res.get('taxonomy_path')}")
            print(f"  combined: {res.get('combined_path')}")
            print(f"  excel: {res.get('excel_out_path')}")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d klasyfikacji LLM: {e}")
    
    if args.continuous:
        cli.run_continuous_analysis(args.interval, args.batch_size)
    
    return success

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nğŸ›‘ Przerwano przez uÅ¼ytkownika")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ BÅ‚Ä…d krytyczny: {e}")
        sys.exit(1)
