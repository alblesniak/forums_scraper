#!/usr/bin/env python3
"""
Interfejs wiersza polece≈Ñ dla analizy token√≥w
Wspiera multiprocessing, tqdm i wyb√≥r for√≥w
"""

import os
import sys
import argparse
import time
from pathlib import Path
from typing import List, Optional

# Dodaj ≈õcie≈ºkƒô do modu≈Çu analizy
sys.path.append(str(Path(__file__).parent))

from tokenization import TokenAnalyzer
from gender_prediction import run_gender_rules, run_gender_rules_into_analysis
from config import get_config
from topic_modeling.batch_classifier import run_batch_classification
from values import run_values_classification
from politics import run_politics_preference_classification

class AnalysisCLI:
    """Interfejs wiersza polece≈Ñ dla analizy"""
    
    def __init__(self):
        self.config = get_config()
        self.analyzer = None
    
    def setup_analyzer(self, source_db: str, analysis_db: str, forums: List[str] = None):
        """Konfiguruje analizator"""
        try:
            # Je≈ºeli fora nie zosta≈Çy podane, pozw√≥l analizatorowi wykryƒá je z bazy
            if forums is None or (isinstance(forums, list) and len(forums) == 0) or forums == ['auto']:
                forums = None
            
            self.analyzer = TokenAnalyzer(
                source_db=source_db,
                analysis_db=analysis_db,
                forums_to_analyze=forums
            )
            
            print(f"‚úÖ Analizator skonfigurowany")
            print(f"   üìç Baza ≈∫r√≥d≈Çowa: {source_db}")
            print(f"   üìç Baza analizy: {analysis_db}")
            if forums is None:
                print(f"   üéØ Fora do analizy: (auto) zostanƒÖ wykryte z bazy")
            else:
                print(f"   üéØ Fora do analizy: {', '.join(forums)}")
            print(f"   ‚ö° Multiprocessing: {'W≈ÇƒÖczone' if self.config['multiprocessing']['use_multiprocessing'] else 'Wy≈ÇƒÖczone'}")
            print(f"   üîß Liczba proces√≥w: {self.config['multiprocessing']['max_workers']}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd konfiguracji analizatora: {e}")
            return False
    
    def create_database(self) -> bool:
        """Tworzy bazƒô analizy"""
        try:
            print("üèóÔ∏è  Tworzenie bazy analizy...")
            
            if self.analyzer.create_analysis_database():
                print("‚úÖ Baza analizy utworzona pomy≈õlnie")
                return True
            else:
                print("‚ùå B≈ÇƒÖd tworzenia bazy analizy")
                return False
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd tworzenia bazy: {e}")
            return False
    
    def show_forums_info(self):
        """Pokazuje informacje o forach"""
        try:
            if not self.analyzer:
                print("‚ùå Analizator nie jest skonfigurowany")
                return False
            
            print("üìä INFORMACJE O FORACH")
            print("=" * 50)
            
            forums_info = self.analyzer.get_forums_info()
            
            for forum in forums_info['forums']:
                print(f"üéØ {forum['name']}")
                print(f"   üìù Wszystkie posty: {forum['total_posts']:,}")
                print(f"   üîç Przeanalizowane: {forum['analyzed_posts']:,}")
                print(f"   üìà Postƒôp: {forum['progress']:.1f}%")
                print()
            
            return True
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd pobierania informacji o forach: {e}")
            return False
    
    def analyze_single_batch(self, batch_size: int) -> bool:
        """Analizuje pojedynczƒÖ partiƒô post√≥w"""
        try:
            if not self.analyzer:
                print("‚ùå Analizator nie jest skonfigurowany")
                return False
            
            print(f"üì¶ Analiza partii {batch_size} post√≥w...")
            
            start_time = time.time()
            processed = self.analyzer.process_batch(batch_size)
            elapsed = time.time() - start_time
            
            if processed > 0:
                print(f"‚úÖ Przetworzono {processed} post√≥w w {elapsed:.2f}s")
                print(f"   ‚ö° Wydajno≈õƒá: {processed/elapsed:.1f} post√≥w/s")
            else:
                print("‚ÑπÔ∏è  Brak post√≥w do analizy")
            
            return True
            
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd analizy partii: {e}")
            return False
    
    def analyze_all_posts(self, show_progress: bool = True) -> bool:
        """Analizuje wszystkie posty z okre≈õlonych for√≥w"""
        try:
            if not self.analyzer:
                print("‚ùå Analizator nie jest skonfigurowany")
                return False
            
            print("üöÄ Rozpoczynam analizƒô wszystkich post√≥w...")
            
            start_time = time.time()
            result = self.analyzer.analyze_all_forums_posts(show_progress=show_progress)
            elapsed = time.time() - start_time
            
            if 'error' not in result:
                print(f"\n‚úÖ Analiza zako≈Ñczona!")
                print(f"   üìù Przeanalizowane posty: {result['total_analyzed']:,}")
                print(f"   üéØ Wszystkie posty: {result['total_posts']:,}")
                print(f"   ‚è±Ô∏è  Czas wykonania: {elapsed:.2f}s")
                print(f"   ‚ö° ≈örednia wydajno≈õƒá: {result['total_analyzed']/elapsed:.1f} post√≥w/s")
                print(f"   üéØ Fora: {', '.join(result['forums_analyzed'])}")
                return True
            else:
                print(f"‚ùå B≈ÇƒÖd analizy: {result['error']}")
                return False
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd analizy wszystkich post√≥w: {e}")
            return False
    
    def show_summary(self):
        """Pokazuje podsumowanie analizy"""
        try:
            if not self.analyzer:
                print("‚ùå Analizator nie jest skonfigurowany")
                return False
            
            print("üìä PODSUMOWANIE ANALIZY")
            print("=" * 50)
            
            summary = self.analyzer.get_analysis_summary()
            
            if summary:
                print(f"üìù Wszystkie posty: {summary['total_posts']:,}")
                print(f"üîç Przeanalizowane: {summary['total_analyzed']:,}")
                print(f"üìà Postƒôp: {summary['analysis_progress']:.1f}%")
                print(f"üî¢ ≈ÅƒÖczna liczba token√≥w: {summary['total_tokens']:,}")
                print(f"üìù ≈ÅƒÖczna liczba s≈Ç√≥w: {summary['total_words']:,}")
                
                # Statystyki dzienne
                if summary['daily_stats']:
                    print(f"\nüìÖ Statystyki dzienne:")
                    for day in summary['daily_stats'][:5]:  # Poka≈º ostatnie 5 dni
                        print(f"   üìÖ {day['date']}: {day['posts_analyzed']} post√≥w, {day['total_tokens']:,} token√≥w")
                
                # Statystyki pamiƒôci
                if 'memory_stats' in summary:
                    mem_stats = summary['memory_stats']
                    print(f"\nüíæ Statystyki pamiƒôci:")
                    print(f"   üîç Posty przeanalizowane: {mem_stats.get('total_posts_analyzed', 0):,}")
                    print(f"   ‚ùå B≈Çƒôdy przetwarzania: {mem_stats.get('processing_errors', 0)}")
                    print(f"   ü§ñ Tokeny spaCy: {mem_stats.get('spacy_tokens', 0):,}")
                    print(f"   üî¢ Tokeny proste: {mem_stats.get('simple_tokens', 0):,}")
                
                return True
            else:
                print("‚ùå Nie uda≈Ço siƒô pobraƒá podsumowania")
                return False
                
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd pobierania podsumowania: {e}")
            return False
    
    def run_continuous_analysis(self, interval: int, batch_size: int):
        """Uruchamia ciƒÖg≈ÇƒÖ analizƒô"""
        try:
            if not self.analyzer:
                print("‚ùå Analizator nie jest skonfigurowany")
                return False
            
            print(f"üîÑ Uruchamiam ciƒÖg≈ÇƒÖ analizƒô (interwa≈Ç: {interval}s, partia: {batch_size})")
            print("   Naci≈õnij Ctrl+C aby zatrzymaƒá")
            
            self.analyzer.start_continuous_analysis(interval, batch_size)
            
        except KeyboardInterrupt:
            print("\nüõë Zatrzymano analizƒô (Ctrl+C)")
            if self.analyzer:
                self.analyzer.stop_continuous_analysis()
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd ciƒÖg≈Çej analizy: {e}")

def main():
    """G≈Ç√≥wna funkcja CLI"""
    parser = argparse.ArgumentParser(
        description="Analiza token√≥w dla post√≥w forum z multiprocessing i tqdm",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Przyk≈Çady u≈ºycia:
  python cli.py --create-db                    # Utw√≥rz bazƒô analizy
  python cli.py --info                         # Poka≈º informacje o forach
  python cli.py --batch 100                    # Analizuj partiƒô 100 post√≥w
  python cli.py --all                          # Analizuj wszystkie posty
  python cli.py --continuous --interval 300    # CiƒÖg≈Ça analiza co 5 minut
  python cli.py --summary                      # Poka≈º podsumowanie
  python cli.py --forums radio_katolik,wiara   # Wybierz fora do analizy
        """
    )
    
    # Opcje bazy danych
    parser.add_argument("--source-db", default="../data/databases/merged_forums.db",
                       help="≈öcie≈ºka do ≈∫r√≥d≈Çowej bazy danych")
    parser.add_argument("--analysis-db", default="../data/databases/analysis_forums.db",
                       help="≈öcie≈ºka do bazy analizy")
    
    # Opcje for√≥w
    parser.add_argument("--forums", 
                       help="Lista for√≥w do analizy (oddzielone przecinkami)")
    
    # Opcje multiprocessing
    parser.add_argument("--no-multiprocessing", action="store_true",
                       help="Wy≈ÇƒÖcz multiprocessing")
    parser.add_argument("--workers", type=int,
                       help="Liczba proces√≥w roboczych")
    parser.add_argument("--chunk-size", type=int,
                       help="Rozmiar chunka dla multiprocessing")
    
    # Akcje
    parser.add_argument("--create-db", action="store_true",
                       help="Utw√≥rz bazƒô analizy")
    parser.add_argument("--info", action="store_true",
                       help="Poka≈º informacje o forach")
    parser.add_argument("--batch", type=int, metavar="SIZE",
                       help="Analizuj partiƒô post√≥w o okre≈õlonym rozmiarze")
    parser.add_argument("--all", action="store_true",
                       help="Analizuj wszystkie posty z okre≈õlonych for√≥w")
    # Nowy etap: predykcja p≈Çci
    parser.add_argument("--gender-rules", action="store_true",
                       help="Uruchom predykcjƒô p≈Çci na podstawie regu≈Ç jƒôzykowych (rules_v1)")
    parser.add_argument("--gender-rules-crossdb", action="store_true",
                       help="Predykcja p≈Çci: czytaj z --source-db (forum_*.db), zapisz do --analysis-db (gender_predictions)")
    parser.add_argument("--continuous", action="store_true",
                       help="Uruchom ciƒÖg≈ÇƒÖ analizƒô")
    parser.add_argument("--summary", action="store_true",
                       help="Poka≈º podsumowanie analizy")
    # Klasyfikacja LLM ws. taksonomii
    parser.add_argument("--llm-classify", action="store_true",
                       help="Uruchom klasyfikacjƒô post√≥w z Excela przez OpenAI Batch API")
    parser.add_argument("--llm-input", type=str, default="data/topics/results/20250821/M/ALL/185832/examples/topic_2_pi_pis_sld.xlsx",
                       help="≈öcie≈ºka do wej≈õciowego pliku Excel z kolumnƒÖ 'content' (i opcjonalnie 'post_id')")
    parser.add_argument("--llm-batch-size", type=int, default=10,
                       help="Rozmiar batcha (liczba post√≥w na job Batch API)")
    parser.add_argument("--llm-interval", type=int, default=10,
                       help="Interwa≈Ç pollingu statusu batcha (sekundy)")
    # Nowy modu≈Ç: warto≈õci (M vs K)
    parser.add_argument("--values", action="store_true",
                       help="Uruchom klasyfikacjƒô odwo≈Ça≈Ñ do warto≈õci (K vs M)")
    parser.add_argument("--values-k", type=str, default="data/topics/results/20250827/K/ALL/155429_038844/examples/POLITYKA_KOBIETY.xlsx",
                       help="≈öcie≈ºka do Excela z postami kobiet (kolumna 'content')")
    parser.add_argument("--values-m", type=str, default="data/topics/results/20250827/M/ALL/194903_560595/examples/POLITYKA_MEZCZYZNI.xlsx",
                       help="≈öcie≈ºka do Excela z postami mƒô≈ºczyzn (kolumna 'content')")
    parser.add_argument("--values-batch-size", type=int, default=10,
                       help="Rozmiar paczki post√≥w przekazywanej do modelu (10)")
    
    # Nowy modu≈Ç: preferencje polityczne (M vs K)
    parser.add_argument("--politics", action="store_true",
                       help="Uruchom klasyfikacjƒô preferencji politycznych (partie/liderzy) dla K i M")
    parser.add_argument("--politics-k", type=str, default="data/topics/results/20250827/K/ALL/155429_038844/examples/POLITYKA_KOBIETY.xlsx",
                       help="≈öcie≈ºka do Excela z postami kobiet do polityki (kolumna 'content')")
    parser.add_argument("--politics-m", type=str, default="data/topics/results/20250827/M/ALL/194903_560595/examples/POLITYKA_MEZCZYZNI.xlsx",
                       help="≈öcie≈ºka do Excela z postami mƒô≈ºczyzn do polityki (kolumna 'content')")
    parser.add_argument("--politics-batch-size", type=int, default=10,
                       help="Rozmiar paczki post√≥w przekazywanej do modelu (10)")

    # Opcje ciƒÖg≈Çej analizy
    parser.add_argument("--interval", type=int, default=300,
                       help="Interwa≈Ç dla ciƒÖg≈Çej analizy w sekundach")
    parser.add_argument("--batch-size", type=int, default=100,
                       help="Rozmiar partii dla analizy")
    
    # Opcje wy≈õwietlania
    parser.add_argument("--no-progress", action="store_true",
                       help="Wy≈ÇƒÖcz paski postƒôpu")
    
    args = parser.parse_args()
    
    # Sprawd≈∫ czy podano akcjƒô
    if not any([args.create_db, args.info, args.batch, args.all, args.continuous, args.summary, args.gender_rules, args.gender_rules_crossdb, args.llm_classify, args.values, args.politics]):
        parser.print_help()
        return False
    
    # Utw√≥rz CLI
    cli = AnalysisCLI()
    
    # Konfiguruj multiprocessing je≈õli podano
    if args.no_multiprocessing:
        cli.config['multiprocessing']['use_multiprocessing'] = False
    
    if args.workers:
        cli.config['multiprocessing']['max_workers'] = args.workers
    
    if args.chunk_size:
        cli.config['multiprocessing']['chunk_size'] = args.chunk_size
    
    # Parsuj fora
    forums = None
    if args.forums:
        forums = [f.strip() for f in args.forums.split(',')]
    
    # Konfiguruj analizator
    if not cli.setup_analyzer(args.source_db, args.analysis_db, forums):
        return False
    
    # Wykonaj akcje
    success = True
    
    if args.create_db:
        success &= cli.create_database()
    
    if args.info:
        success &= cli.show_forums_info()
    
    if args.batch:
        success &= cli.analyze_single_batch(args.batch)
    
    if args.all:
        success &= cli.analyze_all_posts(show_progress=not args.no_progress)
    
    if args.summary:
        success &= cli.show_summary()

    if args.gender_rules:
        # Uruchom prosty predyktor p≈Çci dla wybranych for√≥w (lub wszystkich wykrytych)
        forums_list = forums
        if forums_list is None:
            # Wykryj fora z bazy analizy (tak jak w TokenAnalyzer)
            try:
                import sqlite3
                conn = sqlite3.connect(args.analysis_db)
                cur = conn.cursor()
                cur.execute("SELECT spider_name FROM forums")
                forums_list = [row[0] for row in cur.fetchall()]
                conn.close()
            except Exception:
                forums_list = None
        print("\n=== Predykcja p≈Çci (rules_v1) ===")
        res = run_gender_rules(args.analysis_db, forums=forums_list)
        print(f"U≈ºytkownicy przetworzeni: {res.get('processed_users', 0)}")
        print(f"Zapisane predykcje: {res.get('saved_predictions', 0)}")

    if args.gender_rules_crossdb:
        # Cross-DB: czytamy ze ≈∫r√≥d≈Ça (forum_*.db), zapisujemy do bazy analizy
        forums_list = forums
        if forums_list is None:
            # Wykryj fora ze ≈∫r√≥d≈Ça
            try:
                import sqlite3
                conn = sqlite3.connect(args.source_db)
                cur = conn.cursor()
                cur.execute("SELECT spider_name FROM forums")
                forums_list = [row[0] for row in cur.fetchall()]
                conn.close()
            except Exception:
                forums_list = None

        print("\n=== Predykcja p≈Çci (rules_v1, cross-DB) ===")
        try:
            res = run_gender_rules_into_analysis(
                analysis_db=args.analysis_db,
                source_db=args.source_db,
                forums=forums_list,
            )
            print(f"U≈ºytkownicy przetworzeni: {res.get('processed_users', 0)}")
            print(f"Zapisane predykcje: {res.get('saved_predictions', 0)}")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd predykcji (cross-DB): {e}")
    
    if args.llm_classify:
        print("\n=== Klasyfikacja LLM (Batch API) ===")
        try:
            res = run_batch_classification(
                excel_path=args.llm_input,
                batch_size=args.llm_batch_size,
                poll_interval_s=args.llm_interval,
            )
            print("Wyniki zapisane w:")
            print(f"  run_dir: {res.get('run_dir')}")
            print(f"  taxonomy: {res.get('taxonomy_path')}")
            print(f"  combined: {res.get('combined_path')}")
            print(f"  excel: {res.get('excel_out_path')}")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd klasyfikacji LLM: {e}")
    
    if args.continuous:
        cli.run_continuous_analysis(args.interval, args.batch_size)

    if args.values:
        print("\n=== Klasyfikacja warto≈õci (M vs K) ===")
        try:
            res = run_values_classification(
                k_excel_path=args.values_k,
                m_excel_path=args.values_m,
                batch_size=args.values_batch_size,
                show_progress=not args.no_progress,
            )
            print("Wyniki zapisane w:")
            print(f"  run_dir: {res.get('run_dir')}")
            print(f"  predictions: {res.get('predictions_csv')}")
            print(f"  aggregates: {res.get('aggregates_csv')}")
            print(f"  comparison: {res.get('comparison_csv')}")
            print(f"  examples: {res.get('examples_csv')}")
            print(f"  excel: {res.get('excel_out_path')}")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd klasyfikacji warto≈õci: {e}")

    if args.politics:
        print("\n=== Klasyfikacja preferencji politycznych (K vs M) ===")
        try:
            res = run_politics_preference_classification(
                k_excel_path=args.politics_k,
                m_excel_path=args.politics_m,
                batch_size=args.politics_batch_size,
                show_progress=not args.no_progress,
            )
            print("Wyniki zapisane w:")
            print(f"  run_dir: {res.get('run_dir')}")
            print(f"  predictions: {res.get('predictions_csv')}")
            print(f"  aggregates: {res.get('aggregates_csv')}")
            print(f"  comparison: {res.get('comparison_csv')}")
            print(f"  excel: {res.get('excel_out_path')}")
        except Exception as e:
            print(f"‚ùå B≈ÇƒÖd klasyfikacji preferencji: {e}")
    
    return success

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\nüõë Przerwano przez u≈ºytkownika")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå B≈ÇƒÖd krytyczny: {e}")
        sys.exit(1)
