"""
Zaawansowany interfejs CLI dla forums-scraper z peÅ‚nÄ… konfiguracjÄ… i raportowaniem.
"""

from __future__ import annotations

import json
import subprocess
import sys
import time
from datetime import datetime
from enum import Enum
from pathlib import Path
import os
from typing import Annotated, Dict, List, Optional, Set

import typer
from rich.console import Console
from rich.panel import Panel
from rich.progress import (
    BarColumn, 
    MofNCompleteColumn, 
    Progress, 
    SpinnerColumn, 
    TextColumn, 
    TimeElapsedColumn
)
from rich.table import Table
from rich.text import Text

from core.config import AppConfig, load_config


console = Console()
app = typer.Typer(
    name="forums-scraper",
    help="ðŸ•·ï¸ Zaawansowany scraper forÃ³w religijnych z analizami NLP",
    add_completion=False,
    no_args_is_help=True,
    rich_markup_mode="rich"
)


class AnalysisType(str, Enum):
    """Typy dostÄ™pnych analiz."""
    NONE = "none"
    BASIC_TOKENS = "basic_tokens"
    TOKEN_COUNT = "token_count"
    SPACY_FULL = "spacy_full"
    URL_ANALYSIS = "url_analysis"
    DOMAIN_STATS = "domain_stats"
    ALL = "all"


class ForumName(str, Enum):
    """DostÄ™pne fora do scrapowania."""
    DOLINA_MODLITWY = "dolina_modlitwy"
    RADIO_KATOLIK = "radio_katolik"
    WIARA = "wiara"
    Z_CHRYSTUSEM = "z_chrystusem"
    ALL = "all"


# Mapowanie nazw forÃ³w na nazwy spiderÃ³w
FORUM_SPIDER_MAP = {
    ForumName.DOLINA_MODLITWY: "dolina_modlitwy",
    ForumName.RADIO_KATOLIK: "radio_katolik", 
    ForumName.WIARA: "wiara",
    ForumName.Z_CHRYSTUSEM: "z_chrystusem"
}


def create_analysis_config(
    analysis_types: List[AnalysisType],
    spacy_model: str = "pl_core_news_sm",
    include_sentiment: bool = False,
    batch_size: int = 100
) -> Dict:
    """Tworzy konfiguracjÄ™ analiz na podstawie wybranych typÃ³w."""
    if AnalysisType.NONE in analysis_types:
        return {
            "analysis": {
                "enabled": False,
                "analyzers": []
            }
        }
    
    analyzers = []
    
    if AnalysisType.TOKEN_COUNT in analysis_types or AnalysisType.ALL in analysis_types:
        analyzers.append({
            "name": "token_count",
            "config": {
                "encoding": "cl100k_base"
            }
        })
    
    # BasicTokenizer tylko jeÅ›li nie ma spaCy lub explicitly requested
    if (AnalysisType.BASIC_TOKENS in analysis_types and 
        AnalysisType.SPACY_FULL not in analysis_types and 
        AnalysisType.ALL not in analysis_types):
        analyzers.append({
            "name": "basic_tokenizer",
            "config": {
                "lowercase": True,
                "remove_punctuation": False,
                "min_token_length": 2
            }
        })
    
    if AnalysisType.SPACY_FULL in analysis_types or AnalysisType.ALL in analysis_types:
        analyzers.append({
            "name": "spacy_analyzer",
            "config": {
                "model": spacy_model,
                "include_sentiment": include_sentiment,
                "batch_size": batch_size,
                "max_length": 1000000
            }
        })
    
    if AnalysisType.URL_ANALYSIS in analysis_types or AnalysisType.ALL in analysis_types:
        analyzers.append({
            "name": "url_analyzer",
            "config": {
                "include_domain_analysis": True,
                "include_url_categorization": True,
                "max_urls_per_post": 50
            }
        })
    
    if AnalysisType.DOMAIN_STATS in analysis_types or AnalysisType.ALL in analysis_types:
        analyzers.append({
            "name": "domain_stats",
            "config": {
                "track_popularity": True
            }
        })
    
    return {
        "analysis": {
            "enabled": True,
            "analyzers": analyzers
        }
    }


def save_config_file(config: Dict, path: Path) -> None:
    """Zapisuje konfiguracjÄ™ do pliku YAML."""
    import yaml
    
    with open(path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True, indent=2)


def get_available_spiders() -> List[str]:
    """Pobiera listÄ™ dostÄ™pnych spiderÃ³w."""
    try:
        result = subprocess.run(
            ["scrapy", "list"], 
            capture_output=True, 
            text=True, 
            check=True
        )
        return result.stdout.strip().split('\n')
    except (subprocess.CalledProcessError, FileNotFoundError):
        return list(FORUM_SPIDER_MAP.values())


def display_analysis_summary(analysis_types: List[AnalysisType]) -> None:
    """WyÅ›wietla podsumowanie wybranych analiz."""
    table = Table(title="ðŸ”¬ Wybrane analizy", show_header=True, header_style="bold magenta")
    table.add_column("Typ analizy", style="cyan")
    table.add_column("Opis", style="white")
    table.add_column("Wymagania", style="yellow")
    
    for analysis_type in analysis_types:
        if analysis_type == AnalysisType.NONE:
            table.add_row("Brak", "Tylko scrapowanie bez analiz", "Brak")
        elif analysis_type == AnalysisType.TOKEN_COUNT:
            table.add_row("Liczenie tokenÃ³w", "Liczba tokenÃ³w OpenAI", "tiktoken")
        elif analysis_type == AnalysisType.BASIC_TOKENS:
            table.add_row("Podstawowa tokenizacja", "PodziaÅ‚ na sÅ‚owa + statystyki", "Brak")
        elif analysis_type == AnalysisType.SPACY_FULL:
            table.add_row("PeÅ‚na analiza spaCy", "Lematyzacja, POS, skÅ‚adnia, sentyment", "spacy + model")
        elif analysis_type == AnalysisType.URL_ANALYSIS:
            table.add_row("Analiza URL-Ã³w", "Kategoryzacja domen i linkÃ³w", "Brak")
        elif analysis_type == AnalysisType.DOMAIN_STATS:
            table.add_row("Statystyki domen", "Podstawowe statystyki linkÃ³w", "Brak")
        elif analysis_type == AnalysisType.ALL:
            table.add_row("Wszystkie analizy", "Kompletna analiza + URL-e", "tiktoken + spacy")
    
    console.print(table)


def display_forum_summary(forums: List[ForumName]) -> None:
    """WyÅ›wietla podsumowanie wybranych forÃ³w."""
    table = Table(title="ðŸ›ï¸ Wybrane fora", show_header=True, header_style="bold blue")
    table.add_column("Forum", style="cyan")
    table.add_column("Spider", style="white")
    table.add_column("Opis", style="green")
    
    forum_descriptions = {
        ForumName.DOLINA_MODLITWY: "Forum katolickie - Dolina Modlitwy",
        ForumName.RADIO_KATOLIK: "Forum Radia Katolik",
        ForumName.WIARA: "Forum Wiara.pl",
        ForumName.Z_CHRYSTUSEM: "Forum Z Chrystusem"
    }
    
    for forum in forums:
        if forum == ForumName.ALL:
            for f in ForumName:
                if f != ForumName.ALL:
                    spider = FORUM_SPIDER_MAP[f]
                    desc = forum_descriptions.get(f, "Brak opisu")
                    table.add_row(f.value, spider, desc)
        else:
            spider = FORUM_SPIDER_MAP[forum]
            desc = forum_descriptions.get(forum, "Brak opisu")
            table.add_row(forum.value, spider, desc)
    
    console.print(table)


@app.command(name="scrape")
def scrape_forums(
    forums: Annotated[List[ForumName], typer.Option(
        "--forum", "-f",
        help="Wybierz fora do scrapowania (moÅ¼na wybraÄ‡ wiele)"
    )] = [ForumName.ALL],
    
    analysis: Annotated[List[AnalysisType], typer.Option(
        "--analysis", "-a",
        help="Rodzaje analiz do wykonania (moÅ¼na wybraÄ‡ wiele)"
    )] = [AnalysisType.BASIC_TOKENS],
    
    config_file: Annotated[Optional[Path], typer.Option(
        "--config", "-c",
        help="ÅšcieÅ¼ka do pliku konfiguracyjnego YAML"
    )] = None,
    
    output_dir: Annotated[Path, typer.Option(
        "--output", "-o",
        help="Katalog wyjÅ›ciowy dla baz danych"
    )] = Path("data/databases"),
    
    spacy_model: Annotated[str, typer.Option(
        "--spacy-model",
        help="Model spaCy do analizy jÄ™zykowej"
    )] = "pl_core_news_lg",
    
    include_sentiment: Annotated[bool, typer.Option(
        "--sentiment/--no-sentiment",
        help="WÅ‚Ä…cz analizÄ™ sentymentu"
    )] = False,
    
    batch_size: Annotated[int, typer.Option(
        "--batch-size",
        help="Rozmiar batcha dla analiz",
        min=1, max=1000
    )] = 100,
    
    concurrent_requests: Annotated[int, typer.Option(
        "--concurrent",
        help="Liczba rÃ³wnolegÅ‚ych Å¼Ä…daÅ„",
        min=1, max=64
    )] = 16,
    
    download_delay: Annotated[float, typer.Option(
        "--delay",
        help="OpÃ³Åºnienie miÄ™dzy Å¼Ä…daniami (sekundy)",
        min=0.0, max=10.0
    )] = 0.5,
    
    dry_run: Annotated[bool, typer.Option(
        "--dry-run",
        help="Tylko pokaÅ¼ co zostanie wykonane, nie uruchamiaj"
    )] = False,
    
    verbose: Annotated[bool, typer.Option(
        "--verbose", "-v",
        help="SzczegÃ³Å‚owe logowanie"
    )] = False
):
    """
    ðŸ•·ï¸ Scrapuj wybrane fora z opcjonalnymi analizami NLP.
    
    PrzykÅ‚ady uÅ¼ycia:
    
    â€¢ Scrapuj wszystkie fora z podstawowÄ… tokenizacjÄ…:
      [cyan]forums-scraper scrape[/cyan]
    
    â€¢ Scrapuj tylko Radio Katolik z peÅ‚nÄ… analizÄ… spaCy:
      [cyan]forums-scraper scrape -f radio_katolik -a spacy_full[/cyan]
    
    â€¢ Scrapuj wybrane fora z wszystkimi analizami:
      [cyan]forums-scraper scrape -f wiara -f dolina_modlitwy -a all --sentiment[/cyan]
    """
    
    console.print(Panel.fit(
        "ðŸ•·ï¸ [bold blue]Forums Scraper[/bold blue] - Zaawansowany scraper forÃ³w religijnych",
        style="blue"
    ))
    
    # RozwiÅ„ 'all' na wszystkie fora
    if ForumName.ALL in forums:
        forums = [f for f in ForumName if f != ForumName.ALL]
    
    # WyÅ›wietl podsumowanie
    display_forum_summary(forums)
    display_analysis_summary(analysis)
    
    # UtwÃ³rz katalog wyjÅ›ciowy
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # UtwÃ³rz konfiguracjÄ™
    if not config_file:
        config = create_analysis_config(analysis, spacy_model, include_sentiment, batch_size)
        config_file = output_dir / "scraper_config.yaml"
        save_config_file(config, config_file)
        console.print(f"ðŸ“ Utworzono plik konfiguracyjny: [cyan]{config_file}[/cyan]")
    
    # WyÅ›wietl plan dziaÅ‚ania
    unified_db_path = output_dir / "forums_unified.db"
    console.print("\nðŸŽ¯ [bold]Plan dziaÅ‚ania:[/bold]")
    console.print(f"ðŸ“Š [bold]WspÃ³lna baza danych:[/bold] [yellow]{unified_db_path}[/yellow]")
    for i, forum in enumerate(forums, 1):
        spider_name = FORUM_SPIDER_MAP[forum]
        console.print(f"  {i}. [cyan]{forum.value}[/cyan] (spider: {spider_name})")
    
    if dry_run:
        console.print("\n[yellow]ðŸ” Tryb dry-run - nie wykonujÄ™ scrapowania[/yellow]")
        return
    
    # PotwierdÅº wykonanie
    if not typer.confirm("\nâ“ Czy chcesz kontynuowaÄ‡?"):
        console.print("[red]âŒ Anulowano[/red]")
        return
    
    # Wykonaj scrapowanie
    console.print("\nðŸš€ [bold green]Rozpoczynam scrapowanie...[/bold green]")
    
    total_forums = len(forums)
    failed_forums = []
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        MofNCompleteColumn(),
        TimeElapsedColumn(),
        console=console,
    ) as progress:
        
        main_task = progress.add_task("Scrapowanie forÃ³w", total=total_forums)
        
        for forum in forums:
            spider_name = FORUM_SPIDER_MAP[forum]
            
            progress.update(
                main_task, 
                description=f"ScrapujÄ™ [cyan]{forum.value}[/cyan] ({spider_name})"
            )
            
            try:
                # Przygotuj argumenty dla Scrapy
                scrapy_args = [
                    "scrapy", "crawl", spider_name,
                    "-s", f"FS_CONFIG_PATH={config_file}",
                    "-s", f"SQLITE_DATABASE_PATH={unified_db_path}",
                    "-s", f"CONCURRENT_REQUESTS={concurrent_requests}",
                    "-s", f"DOWNLOAD_DELAY={download_delay}",
                ]
                
                if verbose:
                    scrapy_args.extend(["-s", "LOG_LEVEL=INFO"])
                else:
                    scrapy_args.extend(["-s", "LOG_LEVEL=WARNING"])
                
                # Uruchom Scrapy
                console.print(f"â–¶ï¸  Uruchamiam: [dim]{' '.join(scrapy_args)}[/dim]")
                
                # Uruchamiaj z rootu projektu, aby scrapy.cfg byÅ‚ widoczny
                project_root = Path(__file__).resolve().parents[1]
                env = os.environ.copy()
                env.setdefault("SCRAPY_SETTINGS_MODULE", "forums_scraper.settings")
                result = subprocess.run(
                    scrapy_args,
                    cwd=str(project_root),
                    env=env,
                    capture_output=not verbose,
                    text=True,
                    check=True
                )
                
                console.print(f"âœ… [green]{forum.value} - zakoÅ„czono pomyÅ›lnie[/green]")
                
            except subprocess.CalledProcessError as e:
                console.print(f"âŒ [red]{forum.value} - bÅ‚Ä…d: {e}[/red]")
                failed_forums.append(forum.value)
            
            except KeyboardInterrupt:
                console.print(f"\n[yellow]â¹ï¸  Przerwano przez uÅ¼ytkownika[/yellow]")
                break
                
            progress.advance(main_task)
    
    # Podsumowanie
    console.print(f"\nðŸŽ‰ [bold green]Scrapowanie zakoÅ„czone![/bold green]")
    
    successful_count = total_forums - len(failed_forums)
    console.print(f"âœ… PomyÅ›lnie: [green]{successful_count}/{total_forums}[/green]")
    
    if failed_forums:
        console.print(f"âŒ Niepowodzenia: [red]{len(failed_forums)}[/red]")
        for forum in failed_forums:
            console.print(f"   â€¢ {forum}")
    
    # WyÅ›wietl informacje o bazie danych
    console.print(f"\nðŸ“Š [bold]WspÃ³lna baza danych:[/bold]")
    if unified_db_path.exists():
        size_mb = unified_db_path.stat().st_size / 1024 / 1024
        console.print(f"   ðŸ“ [cyan]{unified_db_path.name}[/cyan] ([yellow]{size_mb:.1f} MB[/yellow])")
        
        # PokaÅ¼ statystyki per forum jeÅ›li baza istnieje
        try:
            import sqlite3
            with sqlite3.connect(unified_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT f.spider_name, f.title, COUNT(p.id) as posts_count
                    FROM forums f
                    LEFT JOIN sections s ON f.id = s.forum_id
                    LEFT JOIN threads t ON s.id = t.section_id
                    LEFT JOIN posts p ON t.id = p.thread_id
                    GROUP BY f.id, f.spider_name, f.title
                    ORDER BY posts_count DESC
                """)
                results = cursor.fetchall()
                
                if results:
                    console.print("\nðŸ“ˆ [bold]Statystyki per forum:[/bold]")
                    for spider_name, title, posts_count in results:
                        console.print(f"   â€¢ [cyan]{spider_name}[/cyan]: [yellow]{posts_count}[/yellow] postÃ³w")
                
                # Statystyki domen
                try:
                    cursor.execute("""
                        SELECT category, COUNT(*) as count, SUM(total_references) as total_refs
                        FROM domains 
                        GROUP BY category 
                        ORDER BY total_refs DESC
                    """)
                    domain_results = cursor.fetchall()
                    
                    if domain_results:
                        console.print("\nðŸŒ [bold]Statystyki domen:[/bold]")
                        for category, count, total_refs in domain_results:
                            console.print(f"   â€¢ [cyan]{category}[/cyan]: [yellow]{count}[/yellow] domen, [green]{total_refs}[/green] odniesieÅ„")
                
                except Exception:
                    pass  # Tabele domen mogÄ… nie istnieÄ‡
                
        except Exception:
            pass  # Ignoruj bÅ‚Ä™dy SQL
    else:
        console.print(f"   ðŸ“ [yellow]{unified_db_path}[/yellow] (zostanie utworzona)")


@app.command(name="list-spiders")
def list_available_spiders():
    """ðŸ“‹ WyÅ›wietl dostÄ™pne spidery."""
    console.print("ðŸ•·ï¸  [bold]DostÄ™pne spidery:[/bold]")
    
    spiders = get_available_spiders()
    for spider in spiders:
        console.print(f"   â€¢ [cyan]{spider}[/cyan]")


@app.command(name="list-analyzers") 
def list_available_analyzers():
    """ðŸ”¬ WyÅ›wietl dostÄ™pne analizatory."""
    from importlib.metadata import entry_points
    
    console.print("ðŸ”¬ [bold]DostÄ™pne analizatory:[/bold]")
    
    try:
        eps = entry_points(group="forums_scraper.analyzers")
        for ep in sorted(eps, key=lambda x: x.name):
            console.print(f"   â€¢ [cyan]{ep.name}[/cyan] - [dim]{ep.value}[/dim]")
    except Exception as e:
        console.print(f"[red]BÅ‚Ä…d podczas pobierania analizatorÃ³w: {e}[/red]")


@app.command(name="config")
def create_config_file(
    output: Annotated[Path, typer.Option(
        "--output", "-o",
        help="ÅšcieÅ¼ka do pliku konfiguracyjnego"
    )] = Path("scraper_config.yaml"),
    
    analysis: Annotated[List[AnalysisType], typer.Option(
        "--analysis", "-a",
        help="Rodzaje analiz do wÅ‚Ä…czenia"
    )] = [AnalysisType.BASIC_TOKENS],
    
    spacy_model: Annotated[str, typer.Option(
        "--spacy-model",
        help="Model spaCy"
    )] = "pl_core_news_lg",
    
    include_sentiment: Annotated[bool, typer.Option(
        "--sentiment/--no-sentiment",
        help="WÅ‚Ä…cz analizÄ™ sentymentu"
    )] = False
):
    """ðŸ“ UtwÃ³rz plik konfiguracyjny dla analiz."""
    
    config = create_analysis_config(analysis, spacy_model, include_sentiment)
    save_config_file(config, output)
    
    console.print(f"ðŸ“ [green]Utworzono plik konfiguracyjny:[/green] [cyan]{output}[/cyan]")
    
    # WyÅ›wietl zawartoÅ›Ä‡
    console.print("\nðŸ“‹ [bold]ZawartoÅ›Ä‡ pliku:[/bold]")
    with open(output, 'r', encoding='utf-8') as f:
        content = f.read()
        console.print(f"[dim]{content}[/dim]")


@app.command(name="analyze")
def analyze_offline(
    config: Annotated[Path, typer.Option(
        "--config", "-c",
        exists=True, readable=True,
        help="ÅšcieÅ¼ka do pliku konfiguracyjnego"
    )],
    
    input_file: Annotated[Path, typer.Option(
        "--input", "-i",
        exists=True, readable=True,
        help="Plik wejÅ›ciowy JSONL"
    )],
    
    output_file: Annotated[Optional[Path], typer.Option(
        "--output", "-o",
        help="Plik wyjÅ›ciowy JSONL (domyÅ›lnie: input.analyzed.jsonl)"
    )] = None
):
    """ðŸ”¬ Uruchom analizy offline na pliku JSONL."""
    
    if not output_file:
        output_file = input_file.parent / f"{input_file.stem}.analyzed.jsonl"
    
    console.print(f"ðŸ”¬ [bold]Analiza offline[/bold]")
    console.print(f"ðŸ“ WejÅ›cie: [cyan]{input_file}[/cyan]")
    console.print(f"ðŸ“ WyjÅ›cie: [cyan]{output_file}[/cyan]")
    console.print(f"âš™ï¸  Konfiguracja: [cyan]{config}[/cyan]")
    
    # Import i uruchomienie analizy (uÅ¼ywamy istniejÄ…cego kodu)
    from .main import analyze as run_analysis
    
    try:
        run_analysis(config, input_file, output_file)
        console.print(f"âœ… [green]Analiza zakoÅ„czona pomyÅ›lnie![/green]")
    except Exception as e:
        console.print(f"âŒ [red]BÅ‚Ä…d podczas analizy: {e}[/red]")
        raise typer.Exit(1)


@app.command(name="status")
def show_status(
    database_path: Annotated[Path, typer.Option(
        "--database", "-d",
        help="ÅšcieÅ¼ka do bazy danych"
    )] = Path("data/databases/forums_unified.db")
):
    """ðŸ“Š PokaÅ¼ status wspÃ³lnej bazy danych i statystyki."""
    
    console.print("ðŸ“Š [bold]Status wspÃ³lnej bazy danych[/bold]")
    
    if not database_path.exists():
        console.print(f"[yellow]Baza danych nie istnieje: {database_path}[/yellow]")
        console.print("ðŸ’¡ Uruchom scrapowanie: [cyan]uv run cli scrape[/cyan]")
        return
    
    # Podstawowe informacje o pliku
    size_mb = database_path.stat().st_size / 1024 / 1024
    mtime = datetime.fromtimestamp(database_path.stat().st_mtime)
    
    console.print(f"ðŸ“ [cyan]{database_path.name}[/cyan]")
    console.print(f"ðŸ“ Rozmiar: [yellow]{size_mb:.1f} MB[/yellow]")
    console.print(f"ðŸ•’ Ostatnia modyfikacja: [green]{mtime.strftime('%Y-%m-%d %H:%M:%S')}[/green]")
    
    # Statystyki z bazy danych
    try:
        import sqlite3
        with sqlite3.connect(database_path) as conn:
            cursor = conn.cursor()
            
            # Statystyki gÅ‚Ã³wne
            cursor.execute("SELECT COUNT(*) FROM forums")
            forums_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM posts")
            posts_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM users")
            users_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM threads")
            threads_count = cursor.fetchone()[0]
            
            # Tabela gÅ‚Ã³wnych statystyk
            main_table = Table(title="ðŸ“ˆ GÅ‚Ã³wne statystyki", show_header=True)
            main_table.add_column("Kategoria", style="cyan")
            main_table.add_column("Liczba", style="yellow")
            
            main_table.add_row("Fora", str(forums_count))
            main_table.add_row("Posty", str(posts_count))
            main_table.add_row("UÅ¼ytkownicy", str(users_count))
            main_table.add_row("WÄ…tki", str(threads_count))
            
            console.print(main_table)
            
            # Statystyki per forum
            cursor.execute("""
                SELECT f.spider_name, f.title, 
                       COUNT(DISTINCT p.id) as posts_count,
                       COUNT(DISTINCT u.id) as users_count,
                       COUNT(DISTINCT t.id) as threads_count
                FROM forums f
                LEFT JOIN sections s ON f.id = s.forum_id
                LEFT JOIN threads t ON s.id = t.section_id
                LEFT JOIN posts p ON t.id = p.thread_id
                LEFT JOIN users u ON p.user_id = u.id
                GROUP BY f.id, f.spider_name, f.title
                ORDER BY posts_count DESC
            """)
            forum_results = cursor.fetchall()
            
            if forum_results:
                forum_table = Table(title="ðŸ“Š Statystyki per forum", show_header=True)
                forum_table.add_column("Forum", style="cyan")
                forum_table.add_column("Posty", style="yellow")
                forum_table.add_column("UÅ¼ytkownicy", style="green")
                forum_table.add_column("WÄ…tki", style="magenta")
                
                for spider_name, title, posts, users, threads in forum_results:
                    forum_table.add_row(
                        spider_name or "Nieznane",
                        str(posts),
                        str(users),
                        str(threads)
                    )
                
                console.print(forum_table)
            
            # Statystyki analiz (jeÅ›li sÄ…)
            try:
                cursor.execute("SELECT COUNT(*) FROM post_token_stats")
                token_stats_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM post_linguistic_stats")
                linguistic_stats_count = cursor.fetchone()[0]
                
                if token_stats_count > 0 or linguistic_stats_count > 0:
                    analysis_table = Table(title="ðŸ”¬ Statystyki analiz", show_header=True)
                    analysis_table.add_column("Typ analizy", style="cyan")
                    analysis_table.add_column("Przeanalizowane posty", style="yellow")
                    
                    if token_stats_count > 0:
                        analysis_table.add_row("Tokenizacja", str(token_stats_count))
                    
                    if linguistic_stats_count > 0:
                        analysis_table.add_row("Analiza jÄ™zykowa", str(linguistic_stats_count))
                    
                    # SprawdÅº NER
                    try:
                        cursor.execute("SELECT COUNT(*) FROM post_ner_stats")
                        ner_stats_count = cursor.fetchone()[0]
                        
                        if ner_stats_count > 0:
                            analysis_table.add_row("Named Entities", str(ner_stats_count))
                    except Exception:
                        pass
                    
                    console.print(analysis_table)
                    
            except Exception:
                pass  # Tabele analiz mogÄ… nie istnieÄ‡
            
    except Exception as e:
        console.print(f"[red]BÅ‚Ä…d podczas odczytu bazy danych: {e}[/red]")


def run():
    """Entry point for the CLI."""
    app()


if __name__ == "__main__":
    run()
